


apiVersion: v1
kind: Job
name: llama-inference-sample
resources:
  gpu: 0  # CPU-only for this example
  vram_gb: 2
  cpu_cores: 4
  ram_gb: 8
  disk_gb: 5
privacy:
  mode: "public"
image: "ghcr.io/opengrid/examples/llm-infer:latest"
cmd: ["python", "run.py", "--prompt", "Explain quantum computing in simple terms"]
inputs:
  artifacts:
    - ipfs://Qm... # Model weights CIDs would go here
outputs:
  to: ipfs
billing:
  max_price_per_hour_usd: 0.50
  payment: "stream"
  verifier: quorum
  redundancy: 2
  deadline_s: 600



